# æœåŠ¡å™¨å¤§æ¨¡å‹ä½¿ç”¨è¯´æ˜

ç›®å‰æœåŠ¡å™¨ä¸Šéƒ¨ç½²2ä¸ªå¤§è¯­è¨€æ¨¡å‹ï¼š`ChatGLM3-6B`, `Baichuan2-13B`ï¼Œå‡ä¸ºé’ˆå¯¹èŠå¤©å¾®è°ƒåçš„æ¨¡å‹ï¼Œä»¥åŠ1ä¸ªæ–‡æœ¬åµŒå…¥æ¨¡å‹`m3e-large`å¯ä¾›ä½¿ç”¨ã€‚

`ChatGLM3-6B`å’Œ`m3e-large`éƒ¨ç½²çš„åœ°å€ä¸º`http://10.58.0.2:6678/v1`ã€‚

`Baichuan2-13B`éƒ¨ç½²çš„åœ°å€ä¸º`http://10.58.0.2:6677/v1`ã€‚

*æç¤ºï¼šæ¨¡å‹å‚æ•°é‡è¾ƒå°ï¼Œç”Ÿæˆå†…å®¹å¯èƒ½ä¸å¯é ã€‚*



## ç›´æ¥å‘é€è¯·æ±‚è°ƒç”¨

è¯·æ±‚çš„æ ¼å¼å‚è€ƒ OpenAI APIæ ¼å¼æ–‡æ¡£ï¼š

https://platform.openai.com/docs/api-reference/chat/

ä»¥ä¸‹æä¾›ä¸€äº›ä¾‹å­ã€‚

### èŠå¤©

é€šè¿‡å‘`$BASE_IP/chat/completions`å‘é€POSTè¯·æ±‚å¯ä»¥è·å–èŠå¤©æ¨¡å‹çš„å›å¤ï¼Œä»¥è°ƒç”¨`ChatGLM3-6B`ä¸ºä¾‹ã€‚

```shell
curl http://10.58.0.2:6678/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer some_key" \
  -d '{
    "model": "xxx",
    "max_tokens": 2048,
    "top_p": 1,
    "temperature": 1,
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'
```

å…¶ä¸­ï¼Œ`some_key`å’Œ`model`å¯ä»¥ä¸ºä»»æ„å­—ç¬¦ä¸²ã€‚å¦‚æœéœ€è¦æ›´æ¢æ¨¡å‹æ¯”å¦‚ä½¿ç”¨`Baichuan-13B`ï¼Œåˆ™éœ€è¦æ›´æ¢è¯·æ±‚ä¸­çš„ç«¯å£å·ã€‚

å¯ä»¥åœ¨è¯·æ±‚bodyä¸­æŒ‡å®šä»¥ä¸‹å‚æ•°ï¼š

- `max_tokens`ï¼ˆä»£è¡¨å¤§æ¨¡å‹åŒ…æ‹¬è¾“å…¥å’Œå›å¤åœ¨å†…çš„tokené‡ä¸Šé™ï¼‰
- `top_p`å’Œ`temperature`ï¼ˆå‡ä¸ºæ§åˆ¶å¤§æ¨¡å‹è¾“å‡ºéšæœºæ€§çš„å‚æ•°ï¼Œå€¼è¶Šå¤§è¾“å‡ºè¶Šéšæœºï¼Œå…·ä½“å«ä¹‰è¯·è‡ªè¡Œæœç´¢ï¼Œå»ºè®®å‘é€è¯·æ±‚æ—¶è‡ªè¡ŒæŒ‡å®šæ•°å€¼ï¼Œå¹¶åœ¨è°ƒæ•´æ—¶åªå•ç‹¬è°ƒæ•´`temperature`ã€‚ä¸ºäº†è·å–ç¨³å®šçš„è¾“å‡ºå¯èƒ½éœ€è¦å°†`temperature`è°ƒè‡³0.3~0.7ï¼‰

`messages`çš„æ ¼å¼å¦‚ä¸Šã€‚å…¶ä¸­ï¼Œå•ä¸ªæ¶ˆæ¯çš„`role`å±æ€§å¯ä»¥ä¸º`system`, `user`æˆ–`assistant`ã€‚å¦‚æœéœ€è¦è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œéœ€è¦ä¿å­˜åº”ç­”çš„`assistant`ä¿¡æ¯å¹¶åŠ å…¥åˆ°ä¸‹ä¸€æ¬¡è¯·æ±‚`messages`ä¸­ã€‚æ­¤å¤„è¯·ç¡®ä¿æœ€åä¸€ä¸ªå¯¹è¯çš„`role`ä¸º`user`ã€‚

åº”ç­”å¦‚ä¸‹ï¼š

```json
{
    "id": "chatcmpl-4ff3c7df87443b72a6e760a8",
    "object": "chat.completion",
    "created": 1699348028,
    "model": "xxx",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "\n Hello! How can I help you today?",
                "name": null,
                "functions": null,
                "function_call": null,
                "metadata": null,
                "tools": null
            },
            "finish_reason": "stop",
            "history": null
        }
    ],
    "usage": {
        "prompt_tokens": 17,
        "total_tokens": 29,
        "completion_tokens": 12
    }
}
```



### åµŒå…¥

åµŒå…¥æ¨¡å‹è´Ÿè´£å°†æ–‡æœ¬è½¬åŒ–ä¸ºå‘é‡ï¼Œè¯·æ±‚æ ¼å¼å¦‚ä¸‹ï¼š

```sh
curl http://10.58.0.2:6678/v1/embeddings \
  -H "Authorization: Bearer some_key" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, there",
    "model": "m3e-large",
    "encoding_format": "float"
  }'
```

åº”ç­”å¦‚ä¸‹ï¼š

```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        0.011802488937973976
			  // å¤§é‡çš„floatæ•°æ®
        0.031155744567513466
      ],
      "index": 0
    }
  ],
  "model": "m3e-large",
  "usage": {
    "prompt_tokens": 24,
    "total_tokens": 24
  }
}
```

è¯¥æ¨¡å‹ä¸»è¦ç”¨äºæ–‡æœ¬å‘é‡æœç´¢ï¼Œç›¸ä¼¼åº¦æ¯”è¾ƒç­‰å·¥ä½œã€‚å¦‚æœéœ€è¦å®ç°æœ¬åœ°çŸ¥è¯†åº“æé—®ç­‰åŠŸèƒ½ï¼Œå¯ä»¥åˆ©ç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹ã€‚



## ä½¿ç”¨ LangChain é›†æˆ

é¦–å…ˆè¯·å®‰è£…LangChainã€‚

```sh
pip install langchain
```

ä¹‹åï¼Œåœ¨Pythonä»£ç ä¸­ï¼Œå°†ç¯å¢ƒå˜é‡çš„API_BASEé‡å®šå‘åˆ°å­¦æ ¡æœåŠ¡å™¨å³å¯ã€‚

```python
import os

# è¯·å°†API_BASEé‡å®šå‘è‡³å­¦æ ¡æœåŠ¡å™¨
os.environ["OPENAI_API_BASE"] = "http://10.58.0.2:6678/v1"
# KEYå¯ä»¥æ˜¯ä»»æ„å­—ç¬¦ä¸²
os.environ["OPENAI_API_KEY"] = "FAKE_KEY"
```

è‡³æ­¤ï¼Œä½ å¯ä»¥ä½¿ç”¨LangChainå°è£…çš„é’ˆå¯¹ OpenAI APIçš„è¯­è¨€æ¨¡å‹ç±»è¿›è¡Œè°ƒç”¨ã€‚

```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

# å¯ä»¥æŒ‡å®šå‚æ•°
chat = ChatOpenAI(temperature=1, top_p=1, max_tokens=2048)
print(chat([HumanMessage(content="ä½ å¥½ï¼")]))
```

è¾“å‡ºï¼š

```python
content='\n ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM3-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚'
```

*ä¹Ÿå¯ä»¥åœ¨å£°æ˜æ—¶å°†api_baseä½œä¸ºå‚æ•°ä¼ å…¥ã€‚*

```python
chatglm = ChatOpenAI(openai_api_base="http://10.58.0.2:6678/v1")
baichuan = ChatOpenAI(openai_api_base="http://10.58.0.2:6677/v1")
```



å…³äºå…¶ä»–ä»»ä½• LangChain çš„ä½¿ç”¨é—®é¢˜ï¼Œè¯·å‚è€ƒæ–‡æ¡£ï¼š

https://python.langchain.com/docs/get_started/introduction



## ä½¿ç”¨ OpenAI åº“é›†æˆ

```python
import openai

openai.api_base = "http://10.58.0.2:6678/v1"
openai.api_key = "FAKE_KEY"


completion = openai.ChatCompletion.create(
    model="xxx",
    messages=[
        {"role": "user", "content": "ä½ å¥½"},
    ],
    stream=False,
)

print(completion.choices[0].message.content)
```

å‚è€ƒå†…å®¹ï¼šhttps://platform.openai.com/docs/introduction/overview