# 服务器大模型使用说明

目前服务器上部署2个大语言模型：`ChatGLM3-6B`, `Baichuan2-13B`，均为针对聊天微调后的模型，以及1个文本嵌入模型`m3e-large`可供使用。

`ChatGLM3-6B`和`m3e-large`部署的地址为`http://10.58.0.2:6678/v1`。

`Baichuan2-13B`部署的地址为`http://10.58.0.2:6677/v1`。

*提示：模型参数量较小，生成内容可能不可靠。*



## 直接发送请求调用

请求的格式参考 OpenAI API格式文档：

https://platform.openai.com/docs/api-reference/chat/

以下提供一些例子。

### 聊天

通过向`$BASE_IP/chat/completions`发送POST请求可以获取聊天模型的回复，以调用`ChatGLM3-6B`为例。

```shell
curl http://10.58.0.2:6678/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer some_key" \
  -d '{
    "model": "xxx",
    "max_tokens": 2048,
    "top_p": 1,
    "temperature": 1,
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'
```

其中，`some_key`和`model`可以为任意字符串。如果需要更换模型比如使用`Baichuan-13B`，则需要更换请求中的端口号。

可以在请求body中指定以下参数：

- `max_tokens`（代表大模型包括输入和回复在内的token量上限）
- `top_p`和`temperature`（均为控制大模型输出随机性的参数，值越大输出越随机，具体含义请自行搜索，建议发送请求时自行指定数值，并在调整时只单独调整`temperature`。为了获取稳定的输出可能需要将`temperature`调至0.3~0.7）

`messages`的格式如上。其中，单个消息的`role`属性可以为`system`, `user`或`assistant`。如果需要进行多轮对话，需要保存应答的`assistant`信息并加入到下一次请求`messages`中。此处请确保最后一个对话的`role`为`user`。

应答如下：

```json
{
    "id": "chatcmpl-4ff3c7df87443b72a6e760a8",
    "object": "chat.completion",
    "created": 1699348028,
    "model": "xxx",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "content": "\n Hello! How can I help you today?",
                "name": null,
                "functions": null,
                "function_call": null,
                "metadata": null,
                "tools": null
            },
            "finish_reason": "stop",
            "history": null
        }
    ],
    "usage": {
        "prompt_tokens": 17,
        "total_tokens": 29,
        "completion_tokens": 12
    }
}
```



### 嵌入

嵌入模型负责将文本转化为向量，请求格式如下：

```sh
curl http://10.58.0.2:6678/v1/embeddings \
  -H "Authorization: Bearer some_key" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, there",
    "model": "m3e-large",
    "encoding_format": "float"
  }'
```

应答如下：

```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        0.011802488937973976
			  // 大量的float数据
        0.031155744567513466
      ],
      "index": 0
    }
  ],
  "model": "m3e-large",
  "usage": {
    "prompt_tokens": 24,
    "total_tokens": 24
  }
}
```

该模型主要用于文本向量搜索，相似度比较等工作。如果需要实现本地知识库提问等功能，可以利用文本嵌入模型。



## 使用 LangChain 集成

首先请安装LangChain。

```sh
pip install langchain
```

之后，在Python代码中，将环境变量的API_BASE重定向到学校服务器即可。

```python
import os

# 请将API_BASE重定向至学校服务器
os.environ["OPENAI_API_BASE"] = "http://10.58.0.2:6678/v1"
# KEY可以是任意字符串
os.environ["OPENAI_API_KEY"] = "FAKE_KEY"
```

至此，你可以使用LangChain封装的针对 OpenAI API的语言模型类进行调用。

```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

# 可以指定参数
chat = ChatOpenAI(temperature=1, top_p=1, max_tokens=2048)
print(chat([HumanMessage(content="你好！")]))
```

输出：

```python
content='\n 你好👋！我是人工智能助手 ChatGLM3-6B，很高兴见到你，欢迎问我任何问题。'
```

*也可以在声明时将api_base作为参数传入。*

```python
chatglm = ChatOpenAI(openai_api_base="http://10.58.0.2:6678/v1")
baichuan = ChatOpenAI(openai_api_base="http://10.58.0.2:6677/v1")
```



关于其他任何 LangChain 的使用问题，请参考文档：

https://python.langchain.com/docs/get_started/introduction



## 使用 OpenAI 库集成

```python
import openai

openai.api_base = "http://10.58.0.2:6678/v1"
openai.api_key = "FAKE_KEY"


completion = openai.ChatCompletion.create(
    model="xxx",
    messages=[
        {"role": "user", "content": "你好"},
    ],
    stream=False,
)

print(completion.choices[0].message.content)
```

参考内容：https://platform.openai.com/docs/introduction/overview